{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SYST1059A – Capstone Project: Business and Advanced Analytics\n",
    "\n",
    "## Predictive Analytics for Oil Well Failures: A Machine Learning Approach\n",
    "\n",
    "## Modeling Analysis Report\n",
    "\n",
    "By: Titilola Oduwole and Jahir Gutierrez\n",
    "\n",
    "Date: June 06, 2024\n",
    "\n",
    "### 1. Outline¶\n",
    "\n",
    "- Data Loading & Preprocessing\n",
    "- Handling Imbalanced Data\n",
    "- Feature Engineering SelectKBest(), RFE and PCA\n",
    "- Data Splitting (Training / Testing / Validation)\n",
    "- Data Modeling: Support Vector Machine, Logistic Regression, Decision Tree, Random Forest, and XGBoost\n",
    "- Benchmark\n",
    "- Visualization Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b664daba30fc10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e06cd2d06b9ed1fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "file_path = r'C:\\Users\\jaarg\\OneDrive\\College_NBCC\\6. Spring term_2024\\Capstone Project\\Databases\\03. Cleaned Database\\ML Well Failures Prediction.csv'\n",
    "data = pd.read_csv(file_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9380a122ac55f30a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data Overview\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e40866b55c1a5df6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Converting Artificial Lift System as a numerical variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e7a82df54e8b13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "count_esp_before = data['Artificial Lift System'].value_counts().get('ESP', 0)\n",
    "print(f\" 'ESP' before One-Hot Encoding: {count_esp_before}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c7ba4ee5bbb027",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Applying One-Hot to Artificial Lift Systems (ESP and ROD & PCP)\n",
    "\n",
    "data['Artificial_Lift_Type'] = data['Artificial Lift System']\n",
    "\n",
    "# Grouping as ESP and ROD and PCP (No rods needed vs rod string needed)\n",
    "data['Artificial Lift System'] = data['Artificial Lift System'].replace({'ROD': 'ROD_PCP', 'PCP': 'ROD_PCP'})\n",
    "one_hot_encoded = pd.get_dummies(data['Artificial Lift System'], prefix='Lift_System')\n",
    "\n",
    "data['Artificial Lift System'] = data['Artificial Lift System'].map({'ESP': 1, 'ROD_PCP': 0})\n",
    "\n",
    "data = pd.concat([data, one_hot_encoded], axis=1)\n",
    "data.drop(columns=['Lift_System_ESP', 'Lift_System_ROD_PCP'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b2d9bc5bb108b89",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "count_esp_after = data['Artificial Lift System'].value_counts().get(1, 0)\n",
    "print(f\"'ESP' before One-Hot Encoding: {count_esp_after}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0de76c8e3ecbd7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Checking the new columns\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "data.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c81ac13c39ff006f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix\n",
    "corr_matrix = data[['Run Life (days)', 'Artificial Lift System', 'Total fluid rate (bls)', 'Fluid Level (ft)', 'Pump Intake (ft)', 'CHP (psi)', 'THP (psi)', 'Chlorides (ppm)', 'BSW (%)']].corr()\n",
    "\n",
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3d68f34e01df9d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Features to visualize\n",
    "df_numeric = data.select_dtypes(include=[float, int])\n",
    "\n",
    "if 'Well Intervention Type' not in data.columns:\n",
    "    data = pd.concat([data, df_numeric['Well Intervention Type']], axis=1)\n",
    "\n",
    "# Plot density plots for each feature\n",
    "df_numeric = data.select_dtypes(include=[float, int])\n",
    "for feature in df_numeric.columns:\n",
    "    if feature != 'Well Intervention Type':\n",
    "        plt.figure()\n",
    "        sns.kdeplot(data=data, x=feature, hue='Well Intervention Type', common_norm=False, fill=True, warn_singular=False)\n",
    "        plt.title(f'Density Plot of {feature}')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3deec7f6861f3ec4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and comments\n",
    "\n",
    "We decided to include the Artificial Lift System in the evaluation of the machine learning model, and for that reason, we applied One-Hot techniques to convert it into a binary variable. Considering that there are 3 different types of ALS, they were grouped as follows according to the equipment configuration: ROD_PCP (requires a rod string for installation) and ESP (rod string installation-free).\n",
    "\n",
    "Correlation matrix | Key observations:\n",
    "Well Intervention Type has a moderate negative correlation with Intervention Category (-0.68), suggesting that certain types of interventions are associated with specific categories, even though Run Life (days) shows a low correlation 0.21 (positive correlation) the development of the ML model can generate important findings for this project.\n",
    "Total Fluid Rate is strongly correlated with BSW (%) (0.67), suggesting that higher fluid rates are associated with higher BSW percentages.\n",
    "Run Life shows a moderate positive correlation with Fluid Level (0.34) and THP (psi) (0.35), indicating these factors might be predictive of the run life of the wells."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9976d039de2895db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imbalanced Data and Oversampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b11831c25fa91f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = data.drop(['Well Intervention Type', 'Well Name', 'START_DATE', 'Stop Date', 'Oil rate (bls)', 'Gas rate (scf)',\n",
    "       'Water rate (bls)', 'Active String?', 'Rift Subsystem', 'Rift Component Primary', 'Rift Cause General', 'Intervention Category', 'String Status', 'Artificial_Lift_Type' ], axis=1)\n",
    "\n",
    "y = data['Well Intervention Type']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db626f1a9cfd5e98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "print(\"Class distribution before resampling:\", counter)\n",
    "print(f\"Shape of X before SMOTE: {X.shape}\")\n",
    "print(f\"Shape of y before SMOTE: {y.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ccfa85c31a3afd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualizing the data imbalance\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.title('Class Distribution Before Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae0100d4da517d35",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Applying oversampling technique: SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fb4f46379e02422",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Standardize features AFTER oversampling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8660932b683f87a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Shape of X_resampled: {X_resampled.shape}\")\n",
    "print(f\"Shape of y_resampled: {y_resampled.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1a354d5d3fef5d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "counter_resampled = Counter(y_resampled)\n",
    "print(\"Class distribution after resampling:\", counter_resampled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56f900421cdd6da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualizing the data imbalance AFTER resampling\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(counter_resampled.keys(), counter_resampled.values())\n",
    "plt.title('Class Distribution After Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4007ad3c587ca90",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and comments\n",
    "\n",
    "After completing the Statistical Analysis and Data Visualization Report, we identified the poor correlations of the variables with 'Run Life (days)' and decided to change the target variable to Well Intervention Type. The development of the ML model includes this feature.\n",
    "\n",
    "To address the data imbalance, SMOTE technique was performed by generating synthetic samples for the minority class, ensuring the model has sufficient data to learn from both classes effectively, thus improving performance and robustness. \n",
    "\n",
    "Note: random_state=42 to ensure reproducibility of results, allowing others to obtain the same resampled dataset and model outcomes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a6701207c43cb92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc2e1f8faa6066fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Feature selection using SelectKBest()\n",
    "# Justification: Chi2 is chosen because it measures the dependence between categorical variables, making it suitable for our categorical target variable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3494c66bfaa5d8b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 'Well Intervention Type' has defined as \"target variable\"\n",
    "\n",
    "selector = SelectKBest(f_classif, k='all') \n",
    "X_new = selector.fit_transform(X_scaled, y_resampled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5adcc901ce43bf5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculated scores for all features (chi2 statistics)\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Chi2 Score': selector.scores_,\n",
    "    'p-Value': selector.pvalues_\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b13bae6f7e96973a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sorting the features by Chi2 score\n",
    "feature_scores_sorted = feature_scores.sort_values('Chi2 Score', ascending=False)\n",
    "print(feature_scores_sorted)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5828832b892efca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualizing the chi2 scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_scores_sorted['Feature'], feature_scores_sorted['Chi2 Score'])\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Chi2 Score')\n",
    "plt.title('Chi2 Scores for Feature Selection')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc4ce7da956b6d09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Features with a statistically significant relationship with the target\n",
    "alpha = 0.05  # Significance level\n",
    "significant_features = feature_scores_sorted[feature_scores_sorted['p-Value'] < alpha]\n",
    "\n",
    "print(f\"\\nSignificant features based on Chi2 test (alpha = {alpha}):\")\n",
    "print(significant_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d9619ffe25a9e5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and comments\n",
    "\n",
    "The output indicates that \"Run Life (days)\" has the highest Chi2 score, suggesting it has the strongest relationship with the target variable, followed by \"BSW (%)\" and \"Fluid Level (ft). This finding is valuable as it aligns with the experience of the engineering personnel working in the field."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81658164f227a856"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE) was selected to iteratively remove the least important features based on a model's coefficients"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f4857c5e3df0d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creating the logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=500, solver='liblinear')\n",
    "\n",
    "# Applying RFE\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=5, step=1)\n",
    "selected_features_rfe = rfe.fit_transform(X_scaled, y_resampled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4349e3d1bd64631d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the selected features\n",
    "selected_features_rfe_df = pd.DataFrame(selected_features_rfe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d6b0308628419d4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Getting the names of the selected features\n",
    "selected_features_rfe_names = X.columns[rfe.get_support()]\n",
    "selected_features_rfe_df.columns = selected_features_rfe_names\n",
    "\n",
    "# Displaying the DataFrame with selected features\n",
    "print(selected_features_rfe_df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c31e950c8326b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The ranking_ attribute contains the feature ranking\n",
    "feature_ranking = pd.Series(rfe.ranking_, index=X.columns).sort_values(ascending=True)\n",
    "print(\"Feature ranking:\")\n",
    "print(feature_ranking.head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91b44910b7748d00",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and comments\n",
    "\n",
    "We used RFE with LogisticRegression as the estimator to select the top 5 features because it helps identify the most significant features: \n",
    "\n",
    "Feature ranking:\n",
    "Total fluid rate (bls)    1\n",
    "Fluid Level (ft)          1\n",
    "BSW (%)                   1\n",
    "Chlorides (ppm)           1\n",
    "Run Life (days)           1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785823d593e70e2b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We selected (PCA) for dimensionality reduction to transform the original features into a smaller set of uncorrelated components, capturing the most variance in the data. We used PCA due to capturing the most variance in the data with uncorrelated components and is computationally efficient."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f72b0817adc0ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Standardize features before PCA \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()  \n",
    "X_pca = pca.fit_transform(X_scaled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7897e74b3a29e23b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Analyzing exp. variance to determine the number of components to keep\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdbbd86f3c2eb3a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Explained variance ratio per component:\")\n",
    "print(explained_variance_ratio)\n",
    "print(\"Cumulative explained variance ratio:\")\n",
    "print(cumulative_explained_variance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33921c18a29e5772",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting exp variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o')\n",
    "plt.title('Scree Plot of Explained Variance Ratio')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477c99faed29395f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting exp variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o')\n",
    "plt.title('Cumulative Explained Variance Ratio')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20fde1265dc9aff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Choosing the number of components\n",
    "\n",
    "n_components = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "print(f\"Number of components to retain 95% variance: {n_components}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78dd455c5bb81820",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4151b9887381289c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and comments\n",
    "\n",
    "Variance Ratio Analysis: after the first component and more gradually after the third component, indicating that the first few components capture most of the data's variability. This suggests that we can reduce the dimensionality of the dataset to 3. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772fa4d6c89e27be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Splitting (Training / Testing / Validation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e348a3b467449010"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = X_pca\n",
    "y = y_resampled\n",
    "\n",
    "# Split into train and test sets (70/30 split)\n",
    "# Justification: We choose a 70/30 split to have sufficient data for training while leaving enough for testing. The StratifiedShuffleSplit ensures that the proportion of classes ('failure' and 'no_failure') is preserved in both sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "# Verify the class distribution in the training and test sets\n",
    "print(\"Class distribution in the training set:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(\"Class distribution in the test set:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))\n",
    "\n",
    "# Size of the datasets\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9cc7c20705b8eae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split train set into train and validation sets (80/20 split of the train set)\n",
    "# Justification: A validation set is created to tune hyperparameters and avoid overfitting. We use 20% of the training data for validation.\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42, stratify=y_train)\n",
    "\n",
    "# Verify the class distribution in the training and test sets\n",
    "print(\"Class distribution in the final training set:\")\n",
    "print(pd.Series(y_train_final).value_counts(normalize=True))\n",
    "print(\"Class distribution in the validation set:\")\n",
    "print(pd.Series(y_val).value_counts(normalize=True))\n",
    "\n",
    "# Size of the datasets\n",
    "print(f\"Final training set size: {X_train_final.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff9d5d3b33680616",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c80e5fd26b491046"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine (SVM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd382546bf16fbfd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Modeling Algorithms - Support Vector Machine (SVM)\n",
    "# Selected for its effectiveness in classification problems with a maximum margin and its ability to handle high-dimensional data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445b826e02d26a65",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Defining pipeline / cross-validation \n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "201dd452b8ee04b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': [0.001, 0.01, 0.1],\n",
    "    'svm__kernel': ['rbf', 'linear']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d05ef19c473ae3a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# GridSearchCV with Cross-validation with 5 folders\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_final, y_train_final)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48d137f0eb739982",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Best model after hyperparameter tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f32d25e176b302e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predictions on the Test Set\n",
    "y_pred = best_model.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70125c3b577efde8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d822bc16b016d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Prediction probabilities for ROC and AUC calculation\n",
    "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ROC and AUC curves\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c433d961925abaa5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting ROC cruve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3196762825281c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478b88c99319c241"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Learning Curve (Underfitting/Overfitting Analysis)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_model, X_train_final, y_train_final, cv=5, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e825baf88c660e38"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting Learning Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.xlabel('Training Examples')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75814e71276f0202"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
